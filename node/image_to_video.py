import torch
import numpy as np

class ImageToVideo:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "å›¾ç‰‡": ("IMAGE",),
                "æ—¶é•¿": ("FLOAT", {
                    "default": 5.0, 
                    "min": 0.1, 
                    "max": 300.0, 
                    "step": 0.1
                }),
                "å¸§ç‡": ("FLOAT", {  # ä¿®æ”¹ä¸ºFLOATç±»å‹
                    "default": 30.0,
                    "min": 1.0,
                    "max": 120.0,
                    "step": 0.1,
                    "display": "slider"
                }),
                "æ‰¹å¤„ç†å¤§å°": ("INT", {
                    "default": 30,
                    "min": 1,
                    "max": 120,
                    "step": 1,
                    "description": "æ¯æ‰¹å¤„ç†çš„å¸§æ•°ï¼Œè¾ƒå°çš„å€¼ä¼šé™ä½å†…å­˜ä½¿ç”¨"
                })
            }
        }
    
    RETURN_TYPES = ("IMAGE", "INT", "FLOAT", "FLOAT")  # æœ€åè¿”å›FLOATç±»å‹å¸§ç‡
    RETURN_NAMES = ("è§†é¢‘å¸§", "æ€»å¸§æ•°", "å®é™…æ—¶é•¿", "å¸§ç‡")
    FUNCTION = "create_video_frames"
    CATEGORY = "ğŸºDDç³»åˆ—èŠ‚ç‚¹"

    def log_progress(self, current, total):
        """è¾“å‡ºè¿›åº¦ä¿¡æ¯"""
        percentage = (current / total) * 100
        print(f"ç”Ÿæˆè¿›åº¦: {current}/{total} å¸§ ({percentage:.1f}%)")

    def create_video_frames(self, å›¾ç‰‡, æ—¶é•¿, å¸§ç‡, æ‰¹å¤„ç†å¤§å°):
        try:
            # è®¡ç®—éœ€è¦çš„æ€»å¸§æ•°ï¼ˆå››èˆäº”å…¥å¤„ç†ï¼‰
            total_frames = int(round(æ—¶é•¿ * å¸§ç‡))
            actual_duration = total_frames / å¸§ç‡  # å®é™…æ—¶é•¿ï¼ˆè€ƒè™‘å¸§æ•°å–æ•´ï¼‰
            
            # åˆå§‹åŒ–è¿›åº¦
            frames_processed = 0
            
            # ç¡®ä¿è¾“å…¥å›¾ç‰‡æ ¼å¼æ­£ç¡®
            if isinstance(å›¾ç‰‡, torch.Tensor):
                if å›¾ç‰‡.ndim == 3:
                    å›¾ç‰‡ = å›¾ç‰‡.unsqueeze(0)
            
            # ä½¿ç”¨æ‰¹å¤„ç†æ–¹å¼ç”Ÿæˆå¸§
            batches = []
            while frames_processed < total_frames:
                # è®¡ç®—å½“å‰æ‰¹æ¬¡åº”å¤„ç†çš„å¸§æ•°
                current_batch_size = min(æ‰¹å¤„ç†å¤§å°, total_frames - frames_processed)
                
                # ä¸ºå½“å‰æ‰¹æ¬¡ç”Ÿæˆå¸§
                batch_frames = å›¾ç‰‡.repeat(current_batch_size, 1, 1, 1)
                batches.append(batch_frames)
                
                # æ›´æ–°è¿›åº¦
                frames_processed += current_batch_size
                self.log_progress(frames_processed, total_frames)
            
            # åˆå¹¶æ‰€æœ‰æ‰¹æ¬¡
            video_frames = torch.cat(batches, dim=0)
            
            print(f"\nè§†é¢‘å¸§ç”Ÿæˆå®Œæˆ:")
            print(f"- æ€»å¸§æ•°: {total_frames}")
            print(f"- å®é™…æ—¶é•¿: {actual_duration:.3f} ç§’")
            print(f"- å¸§ç‡: {å¸§ç‡:.2f} FPS")
            print(f"- å¸§å°ºå¯¸: {video_frames.shape[-2]}x{video_frames.shape[-1]}")
            
            return (video_frames, total_frames, actual_duration, å¸§ç‡)
            
        except Exception as e:
            print(f"é”™è¯¯: ç”Ÿæˆè§†é¢‘å¸§æ—¶å‘ç”Ÿå¼‚å¸¸ - {str(e)}")
            raise e

NODE_CLASS_MAPPINGS = {
    "DD-ImageToVideo": ImageToVideo
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "DD-ImageToVideo": "DD å›¾ç‰‡è½¬è§†é¢‘å¸§"
}
